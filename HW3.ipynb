{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "53a7fec3-38b8-4e7b-bdf5-c533b2d605b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "680c35e8-fe0f-4529-bdf6-afb23cde53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v(filename):\n",
    "    w2v = {}\n",
    "    w2vFile = open(filename, 'r', encoding='utf-8')\n",
    "    w2v_size = int(w2vFile.readline())\n",
    "    w2v_dim = int(w2vFile.readline())\n",
    "    for i in w2vFile:\n",
    "        s = i.split()\n",
    "        v = [float(val) for val in s[1:]]\n",
    "        w2v[s[0].strip()] = v\n",
    "    w2vFile.close()\n",
    "    return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4c8144b2-eb05-4227-ba3d-4c0561f932ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_dict = load_w2v('W2V_150.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "29146d62-d9aa-4548-9c64-c3233c528bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(word: str, model: dict):\n",
    "    if word not in model:\n",
    "        return []\n",
    "    return model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ce458260-561a-4df7-b8ee-4d7fee52cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(train_data_path: str) -> list:\n",
    "    word_pair_list = []\n",
    "    with open(train_data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            splited = line[:-1].split(\" \")\n",
    "            word_pair_list.append([splited[0], splited[1]])\n",
    "\n",
    "    return word_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "39cbff2b-1955-4b87-ac91-7d7502691284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(first_word, second_word):\n",
    "    vector_1 = get_word_vector(first_word, word2vec_dict)\n",
    "    vector_2 = get_word_vector(second_word, word2vec_dict)\n",
    "\n",
    "    if not vector_1 or not vector_2:\n",
    "        return []\n",
    "    return vector_1 + vector_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ef4e5219-e8a7-4112-91c7-80625f5498fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data(antonym_data, synonym_data):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    # antonym data, y=0\n",
    "    for word_pair in antonym_data[0 : round(len(antonym_data)*0.5) ]:\n",
    "        feature = get_feature(word_pair[0], word_pair[1])\n",
    "        if not feature:\n",
    "            continue\n",
    "        y_train.append(0)\n",
    "        x_train.append(feature)\n",
    "    # synomyn data, y=1\n",
    "    for word_pair in synonym_data[0:round(len(synonym_data)*0.5)]:\n",
    "        feature = get_feature(word_pair[0], word_pair[1])\n",
    "        if not feature:\n",
    "            continue\n",
    "        y_train.append(1)\n",
    "        x_train.append(feature)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "31ef2f9e-d598-4639-9645-55b06195c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(test_path: str):\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    word_pair_label_list = []\n",
    "\n",
    "    with open(test_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            splited = line[:-1].split(\"\\t\")\n",
    "            word_pair_label_list.append([splited[0], splited[1], splited[2]])\n",
    "\n",
    "    for word_pair in word_pair_label_list:\n",
    "        feature = get_feature(word_pair[0], word_pair[1])\n",
    "        if not feature:\n",
    "            continue\n",
    "        y_test.append(1 if word_pair[2] == \"SYN\" else 0)\n",
    "        x_test.append(feature)\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c27c314b-7f2f-45c4-9bbd-0e2449e05fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_data = load_train_data(\"./Antonym_vietnamese.txt\")\n",
    "synonym_data = load_train_data(\"./Synonym_vietnamese.txt\")\n",
    "\n",
    "x_train, y_train = generate_train_data(antonym_data, synonym_data)\n",
    "\n",
    "x_test, y_test = generate_test_data(\"./datasets/ViCon-400/400_verb_pairs.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6d5d16de-fdd2-4bd6-bcce-f79152f3996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=400).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b125eae7-d9ea-4868-bf09-f35bef295b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Precision score:  0.6622807017543859\n",
      "Recall score:  0.9869281045751634\n",
      "F1 score:  0.7926509186351706\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_pred_word = clf.predict(np.array([get_feature('đồng_ý', 'từ_chối')]))\n",
    "print(y_pred_word)\n",
    "print(\"Precision score: \", precision_score(y_test, y_pred))\n",
    "print(\"Recall score: \", recall_score(y_test, y_pred))\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d853b-8be4-44eb-b797-d7a53e9fc2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd14d66-9b4b-42f2-9ae6-3df6dcecbded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
